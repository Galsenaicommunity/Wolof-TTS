{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5r7_UsaRyBv"
   },
   "source": [
    "# Traitement et Préparation de Données Audio pour un Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBEeTZ0eSFsz"
   },
   "source": [
    "Ce code est conçu pour lire des fichiers audio au format WAV, les convertir en un format manipulable par NumPy, puis les intégrer dans un dataset au format compatible avec les bibliothèques de machine learning comme Hugging Face datasets. Le processus comprend également un nettoyage du texte associé aux fichiers audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Faozv91xSP0Q"
   },
   "source": [
    "### Importation des Bibliothèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-feqJqvSUmD"
   },
   "source": [
    "Le code commence par l'importation des bibliothèques nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rcfdRHMY6GJ"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JU-vpi28FKMi"
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "from datasets import Dataset, Features, Value, Audio, load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1XzV-ygSobt"
   },
   "source": [
    "##### Bibliothèques utilisées :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dtk_zJttS-b7"
   },
   "source": [
    "\n",
    "\n",
    "*   wave : Utilisé pour manipuler les fichiers audio au format WAV.\n",
    "* numpy : Manipule les données sous forme de tableaux multidimensionnels.\n",
    "* datasets : Une bibliothèque de Hugging Face utilisée pour créer et manipuler des datasets.\n",
    "* pandas : Utilisé pour la gestion et la manipulation des fichiers CSV contenant des métadonnées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyVubIg3TTFk"
   },
   "source": [
    "### Lecture d'un Fichier WAV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibh9cbyaTZTI"
   },
   "source": [
    "La fonction suivante lit un fichier audio au format WAV et renvoie ses données sous forme de tableau NumPy ainsi que la fréquence d'échantillonnage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zQDajpBBS4NC"
   },
   "outputs": [],
   "source": [
    "def read_wav_file(file_path):\n",
    "    \"\"\"Reads a WAV file and returns the audio data as a NumPy array.\n",
    "    Args:\n",
    "        file_path: Path to the WAV file.\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The audio data as a NumPy array.\n",
    "            - The sample rate of the audio.\n",
    "    \"\"\"\n",
    "    with wave.open(file_path, 'rb') as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        sample_width = wf.getsampwidth()\n",
    "        frame_rate = wf.getframerate()\n",
    "        num_frames = wf.getnframes()\n",
    "        audio_data = wf.readframes(num_frames)\n",
    "        audio_data = np.frombuffer(audio_data, dtype=np.int16)\n",
    "        if num_channels == 2:\n",
    "            audio_data = audio_data.reshape(-1, 2)\n",
    "    return audio_data, frame_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-GvsGZLTqpH"
   },
   "source": [
    "#### Explication :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLnRqPKxTx10"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   wave.open() ouvre le fichier audio.\n",
    "\n",
    "*   getnchannels(), getsampwidth(), getframerate(), et getnframes() récupèrent des informations importantes\n",
    " comme le nombre de canaux, la largeur des échantillons, la fréquence d'échantillonnage et le nombre d'images.\n",
    "*   readframes() lit les données audio brutes.\n",
    "\n",
    "\n",
    "*   np.frombuffer() convertit ces données brutes en un tableau NumPy.\n",
    "\n",
    "*   Si le fichier audio a deux canaux (stéréo), il est réorganisé en deux colonnes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC0n8yeDUXYH"
   },
   "source": [
    "### Chargement du Fichier CSV de Métadonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKyjy5kqUeCf"
   },
   "source": [
    "Le fichier CSV est chargé avec pandas et contient les noms des fichiers audio ainsi que le texte associé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_bkB4jzHTvBM"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/metadata.csv', sep='|', \n",
    "                   header=None, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_JwyAWDVwOf"
   },
   "source": [
    "Ici, metadata.csv contient des informations comme le nom des fichiers audio et leur transcription associée. Le séparateur utilisé est le caractère |, et la gestion des lignes incorrectes est configurée pour les sauter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WORGs9kDV4Rh"
   },
   "source": [
    "### Nettoyage et Préparation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz1oYwUnWAP-"
   },
   "source": [
    "La fonction suivante est utilisée pour lire les fichiers audio et nettoyer le texte correspondant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XJDZo97NVz10"
   },
   "outputs": [],
   "source": [
    "def cleaner(el, text):\n",
    "    audio_array, sampling_rate = read_wav_file(f'../../data/wavs/{el}.wav')\n",
    "    text_cleaned = text.replace(';', \"\")\n",
    "    return {\n",
    "        \"text\": text_cleaned,\n",
    "        \"audio\": {\"array\": audio_array, \"sampling_rate\": sampling_rate}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bPZtiSYWin_"
   },
   "source": [
    "#### Explication :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-NdPU18WkVV"
   },
   "source": [
    "\n",
    "\n",
    "*    La fonction cleaner lit les données audio en appelant la fonction read_wav_file() pour chaque fichier mentionné dans le fichier CSV.\n",
    "*   Elle nettoie également le texte associé en supprimant certains caractères indésirables (comme les points-virgules).\n",
    "\n",
    "*   Les données sont ensuite renvoyées sous la forme d'un dictionnaire contenant l'audio (tableau et taux\n",
    " d'échantillonnage), le texte nettoyé, et un attribut de genre (ici fixé à \"female\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QueHi7fmXFNo"
   },
   "source": [
    "### Création d'un Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1wD6NJaXVmt"
   },
   "source": [
    "Le code suivant applique la fonction cleaner à chaque élément et transcription du fichier CSV pour créer une liste de dictionnaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "igEscSopWjxa"
   },
   "outputs": [],
   "source": [
    "dic = [cleaner(el, text) for el, text in zip(data[0], data[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NzwbHsXutP"
   },
   "source": [
    "### Création et Formatage du Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NIOya3zX2U2"
   },
   "source": [
    "Les données sont ensuite transformées en un dataset Hugging Face :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TUYEwBfX8XS"
   },
   "source": [
    "Ensuite, les features (caractéristiques) du dataset sont définies, précisant que la colonne audio contient des données audio, et la colonne text contient des chaînes de caractères.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xYDdqtrHYB5r"
   },
   "outputs": [],
   "source": [
    "features = Features({\n",
    "    'audio': Audio(sampling_rate=44100),\n",
    "    'text' : Value('string'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9aiGwpCRXv28"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(dic, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxmzU4pVYLYI"
   },
   "source": [
    "### Casting du Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1NjKN56YT39"
   },
   "source": [
    "Finalement, les features sont appliquées au dataset en utilisant la méthode cast() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T_-Tmg_3YPbv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f677ae443253426ab65d954923da6b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/19947 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.cast(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDK-O97ZYbSE"
   },
   "source": [
    "Cela assure que les données audio sont correctement formatées avec une fréquence d'échantillonnage de 16 000 Hz et que le texte est reconnu comme des chaînes de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dh1uBJ4YiOH"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvBT9NKxYl98"
   },
   "source": [
    "###  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srcRLgiGYn9I"
   },
   "source": [
    "Ce code permet de transformer des fichiers audio WAV et leurs métadonnées associées en un dataset structuré, prêt à être utilisé dans des tâches de traitement automatique du langage ou d'apprentissage machine, en particulier pour des modèles de Text-to-Speech (TTS) ou de reconnaissance vocale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a3dcc564344527b22d7d11fd6dca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b17c05ba114442eb74f23d53dd35df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e240f2e5984efe86ca82d96952d196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82e544301f44839b11260dff64c30c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5dd6642d374d09a871ebf7c9cc227a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a80d9de1684715a1d178f09f3b910b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d2bfd9eced468a8a361060197dc74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa8f5919f7d4ed684e43fafffba7dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c69a3b2cb54464b554f64fe4bab830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85b064d535e439bae4dd78269d4f704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf712f8c2a2b4951aa418dc1ad2fee8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef0c26f4698488388c8b38dc57dd7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d73f7ed358a4fa8955da82705a49f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3de2eb272af419ab37791a040bf8ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354a9bd73844433db74f06972cab6210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacd09ad9fbb43b69bea5d6f8d1a07cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf46d2b521064f4484ec8ea1c631542b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9694d410cf34962ae69a521d329a155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb3a551c39c48d792284b3ac9aeb0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7147973aad44c5871b13e2380b23a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ebe8da63e546668ad1f996848394a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98910dcd777a4ae582fc5fcca7deda8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa987944e72e40bba51f67f0a63c33eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee86d20a2086406db9227a30f4d85c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c5156e8b2a487f8c3fa7ea51d08543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca6e41de22e40b9900406a9eec241fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/galsenai/anta_women_tts/commit/21e3dae3fba9c8c11cd3dd25f5d21e6136afaa67', commit_message='Upload dataset', commit_description='', oid='21e3dae3fba9c8c11cd3dd25f5d21e6136afaa67', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/galsenai/anta_women_tts', endpoint='https://huggingface.co', repo_type='dataset', repo_id='galsenai/anta_women_tts'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub('galsenai/anta_women_tts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
